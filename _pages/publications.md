---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

<!-- {% if author.googlescholar %}
  You can also find my articles on <u><a href="{{author.googlescholar}}">my Google Scholar profile</a>.</u>
{% endif %}

{% include base_path %} -->

## Peer-Reviewed Conferences

[<span style="font-size:larger;">Meta-in-context learning in large language models.</span>](https://proceedings.neurips.cc/paper_files/paper/2023/file/cda04d7ea67ea1376bf8c6962d8541e0-Paper-Conference.pdf)  
***Julian Coda-Forno**, Marcel Binz, Zeynep Akata, Matthew Botvinick, Jane X Wang, Eric Schulz.*  
*Advances in Neural Information Processing Systems, 36* (2023).

## Conference Workshops
[<span style="font-size:larger;">Leveraging Episodic Memory to Improve World
Models for Reinforcement Learning.</span>](https://memari-workshop.github.io/papers/paper_3.pdf)  
***Julian Coda-Forno**, Changmin Yu, Qinghai Guo, Zafeirios Fountas, Neil Burgess.* *Memory in Artificial and Real Intelligence (MemARI) workshop at NeurIPS* (2022).

## Preprints
[<span style="font-size:larger;">CogBench: a large language model walks into a psychology lab</span>](https://arxiv.org/abs/2402.18225)  
***Julian Coda-Forno**, Marcel Binz, Jane X. Wang, Eric Schulz* (2024).

[<span style="font-size:larger;">Ecologically rational meta-learned inference explains human category learning lab</span>](https://arxiv.org/abs/2402.01821)  
*Akshay K. Jagadish, **Julian Coda-Forno**, Mirko Thalmann, Eric Schulz, and Marcel Binz* (2024).

[<span style="font-size:larger;">Inducing anxiety in large language models increases exploration and bias.</span>](https://arxiv.org/abs/2304.11111)  
***Julian Coda-Forno**, Kristin Witte, Akshay K Jagadish, Marcel Binz, Zeynep Akata, Eric Schulz*  (2023).

[<span style="font-size:larger;">Playing repeated games with Large Language Models.</span>](https://arxiv.org/pdf/2305.16867.pdf)  
*Elif Akata, Lion Schulz, **Julian Coda-Forno**, Seong Joon Oh, Matthias Bethge, Eric Schulz* (2023).

